# Financial-Causality-Detection
Capstone Project
Project id:37


## Abstract:
Transformer-based multilingual question-answering models are used to detect causality in financial text data. This study employs BERT (Devlin et al., 2019) for English text and XLM-RoBERTa (Conneau et al., 2020) for Spanish data, which were fine-tuned on the SQuAD datasets (Rajpurkar et al., 2016), (Rajpurkar et al., 2018). These pre-trained models are used to extract answers to the targeted questions. We design a system using these pre-trained models to answer questions, based on the given context. The results validate the effectiveness of the systems in understanding nuanced financial language and offers a tool for multi-lingual text analysis. Our system is able to achieve SAS scores of 0.75 in Spanish and 0.82 in English.

## Publication URL: 
https://aclanthology.org/2025.finnlp-1.28/

## Paper Title:
PresiUniv at FinCausal 2025 Shared Task: Applying Fine-tuned Language Models to Explain Financial Cause and Effect with Zero-shot Learning

### Publisher: 
Association for Computational Linguistics

### Volume: 
Proceedings of the Joint Workshop of the 9th Financial Technology and Natural Language Processing (FinNLP), the 6th Financial Narrative Processing (FNP), and the 1st Workshop on Large Language Models for Finance and Legal (LLMFinLegal) -- (Pages: 259â€“264)
